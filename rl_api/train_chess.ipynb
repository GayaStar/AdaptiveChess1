{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMqwprwSVCrN"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import chess\n",
        "import chess.engine\n",
        "import pickle\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# ChessNet Model \n",
        "class ChessNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(12, 128, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(256*8*8, 1024)\n",
        "        self.policy_head = nn.Linear(1024, 4672)\n",
        "        self.value_head = nn.Linear(1024, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(-1, 256*8*8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        policy = self.policy_head(x)\n",
        "        value = torch.tanh(self.value_head(x))\n",
        "        return policy, value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rLPnpERX7ed"
      },
      "outputs": [],
      "source": [
        "# Board to Tensor \n",
        "def board_to_tensor(board):\n",
        "    piece_map = {\n",
        "        'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
        "        'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
        "    }\n",
        "    tensor = np.zeros((12, 8, 8), dtype=np.float32)\n",
        "    for square, piece in board.piece_map().items():\n",
        "        idx = piece_map[piece.symbol()]\n",
        "        row, col = divmod(square, 8)\n",
        "        tensor[idx, row, col] = 1\n",
        "    return torch.tensor(tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwFsyMvO9Rq2"
      },
      "outputs": [],
      "source": [
        "# Game Generation \n",
        "def generate_stockfish_games(num_games=100, max_moves=40, depth=4, stockfish_path=\"/usr/games/stockfish\", save_dir=Path(\"games\")):\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "    game_file = save_dir / f\"games_{num_games}_d{depth}.pkl\"\n",
        "\n",
        "    if game_file.exists():\n",
        "        print(\"Loading existing game data...\")\n",
        "        with open(game_file, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "    print(\"Generating new games...\")\n",
        "    engine = chess.engine.SimpleEngine.popen_uci(stockfish_path)\n",
        "    data = []\n",
        "    for _ in range(num_games):\n",
        "        board = chess.Board()\n",
        "        for _ in range(max_moves):\n",
        "            if board.is_game_over():\n",
        "                break\n",
        "            result = engine.play(board, chess.engine.Limit(depth=depth))\n",
        "            move = result.move\n",
        "            state = board_to_tensor(board)\n",
        "            move_idx = move.from_square * 64 + move.to_square\n",
        "            data.append((state, move_idx))\n",
        "            board.push(move)\n",
        "    engine.quit()\n",
        "\n",
        "    with open(game_file, \"wb\") as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYuLWPEdfG-g"
      },
      "outputs": [],
      "source": [
        "# Pretraining\n",
        "def supervised_pretrain(model, data, epochs=5, batch_size=32, pretrained_path=Path(\"chess_pretrained.pth\")):\n",
        "    if pretrained_path.exists():\n",
        "        print(\"Pretrained model found. Skipping training.\")\n",
        "        return\n",
        "\n",
        "    print(\"Starting supervised pretraining...\")\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    states = torch.stack([d[0] for d in data])\n",
        "    moves = torch.tensor([d[1] for d in data])\n",
        "    dataset = TensorDataset(states, moves)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x, y in loader:\n",
        "            optimizer.zero_grad()\n",
        "            policy, _ = model(x)\n",
        "            loss = F.cross_entropy(policy, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader):.4f}\")\n",
        "    torch.save(model.state_dict(), pretrained_path)\n",
        "    print(f\"Saved pretrained model to {pretrained_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkThU3YzfG7p"
      },
      "outputs": [],
      "source": [
        "# Checkpointing \n",
        "def save_checkpoint(model, optimizer, episode, path):\n",
        "    torch.save({\n",
        "        'episode': episode,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, path)\n",
        "\n",
        "def load_checkpoint(model, optimizer, path):\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    return checkpoint['episode']\n",
        "\n",
        "# RL Fine-tuning \n",
        "def rl_finetune(model, episodes=1000, max_moves=40, depth=4, checkpoint_interval=100, checkpoint_dir=Path(\"checkpoints\"), stockfish_path=\"/usr/games/stockfish\"):\n",
        "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    ckpts = sorted(checkpoint_dir.glob(\"*.pth\"))\n",
        "    last_episode = 0\n",
        "    if ckpts:\n",
        "        latest_ckpt = ckpts[-1]\n",
        "        last_episode = load_checkpoint(model, optimizer, latest_ckpt)\n",
        "        print(f\"Resuming from {latest_ckpt.name} (Episode {last_episode})\")\n",
        "    else:\n",
        "        print(\"Starting fresh RL training...\")\n",
        "\n",
        "    engine = chess.engine.SimpleEngine.popen_uci(stockfish_path)\n",
        "\n",
        "    for ep in range(last_episode, episodes):\n",
        "        board = chess.Board()\n",
        "        states, actions, rewards = [], [], []\n",
        "\n",
        "        for _ in range(max_moves):\n",
        "            if board.is_game_over():\n",
        "                break\n",
        "            state = board_to_tensor(board).unsqueeze(0)\n",
        "            with torch.no_grad():\n",
        "                policy_logits, _ = model(state)\n",
        "            legal_moves = list(board.legal_moves)\n",
        "            move_indices = [m.from_square * 64 + m.to_square for m in legal_moves]\n",
        "            policy = torch.softmax(policy_logits[0][move_indices], dim=0).numpy()\n",
        "            move = np.random.choice(legal_moves, p=policy)\n",
        "            move_idx = move.from_square * 64 + move.to_square\n",
        "            states.append(state.squeeze(0))\n",
        "            actions.append(move_idx)\n",
        "            board.push(move)\n",
        "            if board.is_game_over():\n",
        "                break\n",
        "            result = engine.play(board, chess.engine.Limit(depth=depth))\n",
        "            board.push(result.move)\n",
        "\n",
        "        outcome = board.result()\n",
        "        reward = 1 if outcome == \"1-0\" else -1 if outcome == \"0-1\" else 0\n",
        "        rewards = [reward] * len(actions)\n",
        "\n",
        "        for s, a, r in zip(states, actions, rewards):\n",
        "            optimizer.zero_grad()\n",
        "            policy_logits, value = model(s.unsqueeze(0))\n",
        "            loss = F.cross_entropy(policy_logits, torch.tensor([a])) - r * value\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if (ep + 1) % checkpoint_interval == 0:\n",
        "            ckpt_path = checkpoint_dir / f\"checkpoint_ep{ep+1}.pth\"\n",
        "            save_checkpoint(model, optimizer, ep + 1, ckpt_path)\n",
        "            print(f\"Saved checkpoint at episode {ep+1}\")\n",
        "\n",
        "    engine.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR5qsiF-fGfa"
      },
      "outputs": [],
      "source": [
        "def save_model(model, path=\"chess_rl_model.pth\"):\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def load_model(model, path=\"chess_rl_model.pth\"):\n",
        "    model.load_state_dict(torch.load(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WxVqVplfSbx",
        "outputId": "094fa362-e2f3-487f-8a2b-12023d93d0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating new games...\n",
            "Starting supervised pretraining...\n",
            "Epoch 1, Loss: 5.9100\n",
            "Epoch 2, Loss: 4.9378\n",
            "Epoch 3, Loss: 4.5588\n",
            "Saved pretrained model to chess_pretrained.pth\n",
            "Starting fresh RL training...\n",
            "Saved checkpoint at episode 50\n",
            "Saved checkpoint at episode 100\n",
            "Saved checkpoint at episode 150\n",
            "Saved checkpoint at episode 200\n",
            "Saved checkpoint at episode 250\n",
            "Saved checkpoint at episode 300\n",
            "Final model saved to chess_rl_model_final.pth\n"
          ]
        }
      ],
      "source": [
        "# SET PATHS\n",
        "stockfish_path = \"/usr/games/stockfish\"\n",
        "data_dir = Path(\"games\")\n",
        "checkpoint_dir = Path(\"checkpoints\")\n",
        "pretrained_path = Path(\"chess_pretrained.pth\")\n",
        "final_model_path = Path(\"chess_rl_model_final.pth\")\n",
        "\n",
        "# Step 1: Load or generate game data\n",
        "data = generate_stockfish_games(num_games=200, max_moves=40, depth=4,\n",
        "                                stockfish_path=stockfish_path, save_dir=data_dir)\n",
        "\n",
        "# Step 2: Pretrain if not already done\n",
        "model = ChessNet()\n",
        "supervised_pretrain(model, data, epochs=3, batch_size=32, pretrained_path=pretrained_path)\n",
        "\n",
        "# Step 3: RL fine-tuning (resumes if checkpoints exist)\n",
        "load_model(model, pretrained_path)\n",
        "rl_finetune(model, episodes=300, max_moves=40, depth=4,\n",
        "            checkpoint_interval=50, checkpoint_dir=checkpoint_dir,\n",
        "            stockfish_path=stockfish_path)\n",
        "\n",
        "# Step 4: Save final model\n",
        "save_model(model, final_model_path)\n",
        "print(f\"Final model saved to {final_model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EaXc5k3QgAWI",
        "outputId": "2741bad9-ace7-4d7b-e0a9-69ef47325f62"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_cefe179b-d228-4a0d-824a-e4485879626b\", \"chess_pretrained.pth\", 89873538)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_0bfeb18f-06c6-409a-8bc3-4bb427680905\", \"chess_rl_model_final.pth\", 89873602)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download pretrained model\n",
        "files.download(\"chess_pretrained.pth\")\n",
        "\n",
        "# Download final RL-trained model\n",
        "files.download(\"chess_rl_model_final.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "T065ImLpd63e",
        "outputId": "86028509-d2a6-44d4-e08e-087cf0e54d49"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_69e8786f-4e02-4e7c-a2c4-e0f00ea161d4\", \"games.zip\", 405468)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_b2ab2aaa-a000-4889-b03a-f204bc93ff2e\", \"checkpoints.zip\", 650981687)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Zip the games folder\n",
        "shutil.make_archive(\"games\", 'zip', \"games\")\n",
        "\n",
        "# Zip the checkpoints folder\n",
        "shutil.make_archive(\"checkpoints\", 'zip', \"checkpoints\")\n",
        "\n",
        "# Download the zipped folders\n",
        "files.download(\"games.zip\")\n",
        "files.download(\"checkpoints.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLZbY8GFeYTK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
